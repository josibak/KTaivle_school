{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","collapsed_sections":["w90Vwj0Q75GK","zTJGkaEw75GL"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cVB9pY-v8uv5"},"source":["# **성능 최적화 : 층과 노드 수**\n","\n","* 노드 수와 layer 수에 따른 성능 관찰\n","* 성능의 추세 확인"]},{"cell_type":"markdown","source":["* 패션 아이템 이미지 10가지 분류하기\n","    * 데이터 : 이미지(1, 32, 32)\n","    * 10가지 클래스로 분류하기 위한 모델 생성  \n","\n","    \n","\n","![](https://www.researchgate.net/publication/346405197/figure/fig3/AS:962581560848384@1606508736352/Examples-of-Fashion-MNIST-dataset.ppm)"],"metadata":{"id":"22uOfqUgRQ7i"}},{"cell_type":"markdown","source":["\n","## 1.환경준비"],"metadata":{"id":"lW7rbAFn75GD"}},{"cell_type":"markdown","metadata":{"id":"dWZsTNke75GJ"},"source":["### (1) 라이브러리 Import"]},{"cell_type":"code","metadata":{"id":"y0OniRz975GK"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n","from sklearn.metrics import *\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, TensorDataset, Subset\n","from torch.optim import Adam\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","from torchsummary import summary"],"metadata":{"id":"zAo9-47375GK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (2) 필요 함수 생성"],"metadata":{"id":"w90Vwj0Q75GK"}},{"cell_type":"markdown","source":["* 딥러닝을 위한 데이터로더 만들기"],"metadata":{"id":"fQifwT4175GK"}},{"cell_type":"code","source":["def make_DataSet(x_train, x_val, y_train, y_val, batch_size = 32) :\n","\n","    # 데이터 텐서로 변환\n","    x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n","    y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # long = int64\n","    x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n","    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n","\n","    # TensorDataset 생성 : 텐서 데이터셋으로 합치기\n","    train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n","\n","    # DataLoader 생성\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n","\n","    return train_loader, x_val_tensor, y_val_tensor"],"metadata":{"id":"MJKdE57-75GK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 학습을 위한 함수"],"metadata":{"id":"FqpKG76E75GK"}},{"cell_type":"code","source":["def train(dataloader, model, loss_fn, optimizer, device):\n","    size = len(dataloader.dataset)                  # 전체 데이터셋의 크기\n","    num_batches = len(dataloader)                   # 배치 크기\n","    tr_loss = 0\n","    model.train()                                   # 훈련 모드로 설정(드롭아웃 및 배치 정규화와 같은 계층을 훈련 모드로 변경)\n","    for batch, (X, y) in enumerate(dataloader):     # batch : 현재 배치 번호, (X, y) : 입력 데이터와 레이블\n","        X, y = X.to(device), y.to(device)           # X.to(device), y.to(device): 입력 데이터와 레이블을 지정된 장치(device, CPU 또는 GPU)로 이동\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","        tr_loss += loss\n","\n","        # Backpropagation\n","        loss.backward()             # 역전파를 통해 모델의 각 파라미터에 대한 손실의 기울기를 계산\n","        optimizer.step()            # 옵티마이저가 계산된 기울기를 사용하여 모델의 파라미터를 업데이트\n","        optimizer.zero_grad()       # 옵티마이저의 기울기 값 초기화. 기울기가 누적되는 것 방지\n","\n","    tr_loss /= num_batches          # 모든 배치에서의 loss 평균\n","\n","    return tr_loss.item()"],"metadata":{"id":"Ny-dpd9D75GK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 검증을 위한 함수"],"metadata":{"id":"PEzOHqzR75GK"}},{"cell_type":"code","source":["def evaluate(x_val_tensor, y_val_tensor, model, loss_fn, device):\n","    model.eval()                        # 모델을 평가 모드로 설정\n","\n","    with torch.no_grad():               # 평가 과정에서 기울기를 계산하지 않도록 설정(메모리 사용을 줄이고 평가 속도를 높입니다.)\n","        x, y = x_val_tensor.to(device), y_val_tensor.to(device)\n","        pred = model(x)\n","        eval_loss = loss_fn(pred, y).item()    # 예측 값 pred와 실제 값 y 사이의 손실 계산\n","\n","    return eval_loss, pred"],"metadata":{"id":"Db0heZpT75GK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 학습곡선"],"metadata":{"id":"QnJAadAd75GL"}},{"cell_type":"code","source":["def dl_learning_curve(tr_loss_list, val_loss_list, val_acc_list):\n","\n","    epochs = list(range(1, len(tr_loss_list)+1))\n","    plt.plot(epochs, tr_loss_list, label='train_err', marker = '.')\n","    plt.plot(epochs, val_loss_list, label='val_err', marker = '.')\n","    plt.plot(epochs, val_acc_list, label='val_acc', marker = '.')\n","\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend()\n","    plt.grid()\n","    plt.show()"],"metadata":{"id":"l5AMS0f275GL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (3) device 준비(cpu or gpu)"],"metadata":{"id":"zTJGkaEw75GL"}},{"cell_type":"code","source":["# cpu 혹은 gpu 사용\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"],"metadata":{"id":"umbNlljr75GL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (4) 데이터 셋"],"metadata":{"id":"SbROtJmk75GL"}},{"cell_type":"markdown","source":["* 다운로드"],"metadata":{"id":"cW983hn775GL"}},{"cell_type":"code","metadata":{"id":"is_BSzpa75GL"},"source":["train_dataset = datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor())\n","test_dataset = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 데이터 축소\n","    * 다양한 실험을 하기 위해 데이터 사이즈를 줄여서 진행합니다.\n","    * 아래 코드는 흐름만 살펴보세요. 하나하나 다 이해할 필요는 없습니다."],"metadata":{"id":"atzbnTmBbEVw"}},{"cell_type":"code","source":["# 데이터와 레이블 추출\n","train_data = train_dataset.data.numpy() / 255\n","train_labels = train_dataset.targets.numpy()\n","test_data = test_dataset.data.numpy() / 255\n","test_labels = test_dataset.targets.numpy()\n","\n","# 데이터 샘플링, 층화추출\n","x_train, _, y_train, _ = train_test_split(train_data, train_labels, test_size = 40000, random_state = 10, stratify = train_labels)\n","x_val, x_test, y_val, y_test = train_test_split(test_data, test_labels, test_size = 5000, random_state = 10, stratify = test_labels)\n","\n","# 3 --> 4차원으로 변환\n","x_train = x_train.reshape(20000, 1, 28, 28)\n","x_val = x_val.reshape(5000, 1, 28, 28)\n","x_test = x_test.reshape(5000, 1, 28, 28)\n","\n","# tensor로 변환\n","x_train = torch.tensor(x_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.long)\n","x_val = torch.tensor(x_val, dtype=torch.float32)\n","y_val = torch.tensor(y_val, dtype=torch.long)\n","x_test = torch.tensor(x_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.long)\n","\n","# train_dataset으로 변환\n","train_TensorDS = TensorDataset(x_train, y_train)"],"metadata":{"id":"gdlbFDBC-UCf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 데이터셋의 x와 y"],"metadata":{"id":"u6LzElOY75GL"}},{"cell_type":"code","source":["x_train.shape, y_train.shape"],"metadata":{"id":"1iPcKJt575GL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_val.shape, x_test.shape"],"metadata":{"id":"lz-aTrpR6lkx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* y(target)의 클래스"],"metadata":{"id":"E-ag-x1d75GM"}},{"cell_type":"code","source":["classes = train_dataset.classes\n","classes"],"metadata":{"id":"ZbY0sVOK75GM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* train은 데이터로더로 생성"],"metadata":{"id":"jqPl1yF8_y_k"}},{"cell_type":"code","source":["batch_size = 64\n","train_dataloader = DataLoader(train_TensorDS, batch_size=batch_size)"],"metadata":{"id":"tI52JO5HAMia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 첫번째 배치만 로딩해서 살펴보기\n","for X, y in train_dataloader:\n","    print(f\"Shape of X [batch, channels, height, width]: {X.shape}\")\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"],"metadata":{"id":"ppJiUE-hAaDo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BYr1vtpd8uw4"},"source":["## 2.모델링 : Simple"]},{"cell_type":"markdown","metadata":{"id":"H0JLu5wP2Ka3"},"source":["### (1) 모델 선언"]},{"cell_type":"code","metadata":{"id":"3hkvZUsQ4-jZ"},"source":["n_feature = 28 * 28\n","n_class = 10\n","\n","# 모델 구조 설계\n","model = nn.Sequential(nn.Flatten(),               # 이미지를 옆으로 펼치기(한 행에 데이터를 넣기)\n","                      nn.Linear(28*28, 20),\n","                      nn.ReLU(),\n","                      nn.Linear(20, n_class)\n","        ).to(device)\n","\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Loss function과 Optimizer"],"metadata":{"id":"M1eohQRI4-ji"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmR4TlQo4-ji"},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","source":["### (2) 학습"],"metadata":{"id":"pKU0G8Rc2Ka3"}},{"cell_type":"code","source":["epochs = 20\n","tr_loss_list, val_loss_list, val_acc_list = [], [], []\n","\n","for t in range(epochs):\n","    tr_loss = train(train_dataloader, model, loss_fn, optimizer, device)\n","    val_loss, pred = evaluate(x_val, y_val, model, loss_fn, device)\n","\n","    # accuracy 측정\n","    pred = nn.functional.softmax(pred, dim=1)\n","    pred = np.argmax(pred.cpu().numpy(), axis = 1)\n","    acc = accuracy_score(y_val.numpy(), pred)\n","\n","    # 리스트에 추가\n","    tr_loss_list.append(tr_loss)     # train - CrossEntropy\n","    val_loss_list.append(val_loss)   # val - CrossEntropy\n","    val_acc_list.append(acc)         # val - Accuracy\n","\n","    print(f\"Epoch {t+1}, train loss : {tr_loss:.4f}, val loss : {val_loss:.4f}, val acc : {acc:.4f}\")\n","\n","# 학습곡선\n","dl_learning_curve(tr_loss_list, val_loss_list, val_acc_list)"],"metadata":{"id":"Q8En7EdyZPXk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 학습 곡선"],"metadata":{"id":"KhS0sy8u6tHZ"}},{"cell_type":"code","source":["dl_learning_curve(tr_loss_list, val_loss_list, val_acc_list)"],"metadata":{"id":"H4C8tLHN6uqb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (3) 모델 평가"],"metadata":{"id":"VhlqfScB2Ka4"}},{"cell_type":"code","metadata":{"id":"SLWZ7FHz2Ka4"},"source":["_, pred = evaluate(x_test, y_test, model, loss_fn, device)\n","pred = nn.functional.softmax(pred, dim=1)\n","pred = np.argmax(pred.cpu().numpy(), axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* confusion matrix"],"metadata":{"id":"Zl6zoaP5EtXg"}},{"cell_type":"code","source":["cm = confusion_matrix(y_test.numpy(), pred)\n","cm"],"metadata":{"id":"EBhSg5MbEwEn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# confusion matrix 시각화\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n","disp.plot()\n","plt.xticks(rotation=90)\n","plt.show()"],"metadata":{"id":"iE1f2vvVFLJz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* classification_report"],"metadata":{"id":"M3o11w6VGIXS"}},{"cell_type":"code","source":["print(accuracy_score(y_test.numpy(), pred))\n","print('-'*100)\n","print(classification_report(y_test.numpy(), pred, target_names=classes))"],"metadata":{"id":"hjugtOvCGKkL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eIG1zdy0Fg8h"},"source":["## 3.모델링 실험1 : 은닉층 node 증가\n","* 모델 구조를 그대로 두고\n","* 은닉층 노드 수(커널 수)만 늘려 봅시다.\n","    * 예시 : 20 --> 50 --> 128 --> 256 --> 512"]},{"cell_type":"markdown","metadata":{"id":"DGUFiGPxFg8r"},"source":["### (1) 모델 선언"]},{"cell_type":"code","metadata":{"id":"rV5jmrbWFg8r"},"source":["n_feature = 28 * 28\n","n_class = 10\n","node = 20            # 이 숫자를 변경해 가며 성능을 확인해 봅시다.\n","\n","# 모델 구조 설계\n","model = nn.Sequential(nn.Flatten(),               # 이미지를 옆으로 펼치기(한 행에 데이터를 넣기)\n","                      nn.Linear(28*28, node),\n","                      nn.ReLU(),\n","                      nn.Linear(node, n_class)\n","        ).to(device)\n","\n","print(model)\n","# loss, optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=0.001)\n","\n","summary(model, input_size = (1,28,28))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (2) 학습"],"metadata":{"id":"xyTR2PMJFg8s"}},{"cell_type":"code","source":["epochs = 20\n","tr_loss_list, val_loss_list, val_acc_list = [], [], []\n","\n","for t in range(epochs):\n","    tr_loss = train(train_dataloader, model, loss_fn, optimizer, device)\n","    val_loss, pred = evaluate(x_val, y_val, model, loss_fn, device)\n","\n","    # accuracy 측정\n","    pred = nn.functional.softmax(pred, dim=1)\n","    pred = np.argmax(pred.cpu().numpy(), axis = 1)\n","    acc = accuracy_score(y_val.numpy(), pred)\n","\n","    # 리스트에 추가\n","    tr_loss_list.append(tr_loss)     # train - CrossEntropy\n","    val_loss_list.append(val_loss)   # val - CrossEntropy\n","    val_acc_list.append(acc)         # val - Accuracy\n","\n","    print(f\"Epoch {t+1}, train loss : {tr_loss:.4f}, val loss : {val_loss:.4f}, val acc : {acc:.4f}\")\n","\n","# 학습곡선\n","dl_learning_curve(tr_loss_list, val_loss_list, val_acc_list)"],"metadata":{"id":"f6TZ-w7zFg8s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (3) 모델 평가"],"metadata":{"id":"6M7o-4ncFg8s"}},{"cell_type":"code","metadata":{"id":"fdWzwuozFg8s"},"source":["# 예측\n","_, pred = evaluate(x_test, y_test, model, loss_fn, device)\n","pred = nn.functional.softmax(pred, dim=1)\n","pred = np.argmax(pred.cpu().numpy(), axis = 1)\n","\n","# confusion matrix\n","cm = confusion_matrix(y_test.numpy(), pred)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n","disp.plot()\n","plt.xticks(rotation=90)\n","plt.show()\n","\n","# classification report\n","print('='*80)\n","print(f'Accuracy : {accuracy_score(y_test.numpy(), pred)}')\n","print('-'*80)\n","print(classification_report(y_test.numpy(), pred, target_names=classes))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ut3Z5vRvGcg0"},"source":["## 4.모델링 실험2 : 은닉층 증가\n","* 모델 구조에서 은닉층을 늘려 봅시다.\n","    * 1 --> 2 --> 3 --> 4 --> 5\n","    * 각 은닉층의 노드 수는 동일하게 128로 지정\n"]},{"cell_type":"markdown","metadata":{"id":"Y-3GCDGHGcg8"},"source":["#### 1) 모델 선언"]},{"cell_type":"code","metadata":{"id":"H5nZsKHyGcg8"},"source":["n_feature = 28 * 28\n","n_class = 10\n","node = 128\n","\n","# 모델 구조 설계\n","model = nn.Sequential(nn.Flatten(),\n","                      nn.Linear(n_feature, node),\n","\n","\n","\n","                      nn.Linear(node, n_class)\n","        ).to(device)\n","\n","print(model)\n","# loss, optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=0.001)\n","\n","summary(model, input_size = (1,28,28))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) 학습"],"metadata":{"id":"Z68bJrjRGcg9"}},{"cell_type":"code","source":["epochs = 40\n","tr_loss_list, val_loss_list, val_acc_list = [], [], []\n","\n","for t in range(epochs):\n","    tr_loss = train(train_dataloader, model, loss_fn, optimizer, device)\n","    val_loss, pred = evaluate(x_val, y_val, model, loss_fn, device)\n","\n","    # accuracy 측정\n","    pred = nn.functional.softmax(pred, dim=1)\n","    pred = np.argmax(pred.cpu().numpy(), axis = 1)\n","    acc = accuracy_score(y_val.numpy(), pred)\n","\n","    # 리스트에 추가\n","    tr_loss_list.append(tr_loss)     # train - CrossEntropy\n","    val_loss_list.append(val_loss)   # val - CrossEntropy\n","    val_acc_list.append(acc)         # val - Accuracy\n","\n","    print(f\"Epoch {t+1}, train loss : {tr_loss:.4f}, val loss : {val_loss:.4f}, val acc : {acc:.4f}\")\n","\n","# 학습곡선\n","dl_learning_curve(tr_loss_list, val_loss_list, val_acc_list)"],"metadata":{"id":"ZY7lec_BGcg9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3) 모델 평가"],"metadata":{"id":"XDv8tVjuGcg9"}},{"cell_type":"code","metadata":{"id":"_JO5EusfGcg9"},"source":["# 예측\n","_, pred = evaluate(x_test, y_test, model, loss_fn, device)\n","pred = nn.functional.softmax(pred, dim=1)\n","pred = np.argmax(pred.cpu().numpy(), axis = 1)\n","\n","# confusion matrix\n","cm = confusion_matrix(y_test.numpy(), pred)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n","disp.plot()\n","plt.xticks(rotation=90)\n","plt.show()\n","\n","# classification report\n","print('='*80)\n","print(f'Accuracy : {accuracy_score(y_test.numpy(), pred)}')\n","print('-'*80)\n","print(classification_report(y_test.numpy(), pred, target_names=classes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FojtoDUY3kVy"},"execution_count":null,"outputs":[]}]}